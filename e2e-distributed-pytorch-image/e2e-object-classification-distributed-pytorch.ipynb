{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b1aadfd2",
      "metadata": {},
      "source": [
        "# Distributed PyTorch Image Classification\n",
        "# Tutorial\n",
        "\n",
        "**Learning Objectives** - By the end of this tutorial you should be able to use Azure Machine Learning (AzureML) to:\n",
        "- quickly implement basic commands for data preparation\n",
        "- test and run a multi-node multi-gpu pytorch job\n",
        "- use mlflow to analyze your metrics\n",
        "\n",
        "**Requirements** - In order to benefit from this tutorial, you need:\n",
        "- to have provisioned an AzureML workspace\n",
        "- to have permissions to provision a minimal cpu and gpu cluster or simply use [serverless compute (preview)](https://learn.microsoft.com/azure/machine-learning/how-to-use-serverless-compute?view=azureml-api-2&tabs=python)\n",
        "- to have [installed Azure Machine Learning Python SDK v2](https://github.com/Azure/azureml-examples/blob/sdk-preview/sdk/README.md)\n",
        "\n",
        "**Motivations** - Let's consider the following scenario: we want to explore training different image classifiers on distinct kinds of problems, based on a large public dataset that is available at a given url. This ML pipeline will be future-looking, in particular we want:\n",
        "- **genericity**: to be fairly independent from the data we're ingesting (so that we could switch to internal proprietary data in the future),\n",
        "- **configurability**: to run different versions of that training with simple configuration changes,\n",
        "- **scalability**: to iterate on the pipeline on small sample, then smoothly transition to running at scale.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6641f516",
      "metadata": {},
      "source": [
        "### Connect to AzureML\n",
        "\n",
        "Before we dive in the code, we'll need to create an instance of MLClient to connect to Azure ML.\n",
        "\n",
        "We are using `DefaultAzureCredential` to get access to workspace. `DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios.\n",
        "\n",
        "Reference for more available credentials if it does not work for you: [configure credential example](https://github.com/Azure/azureml-examples/blob/sdk-preview/sdk/jobs/configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c92cd1bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# authentication package\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c8791906",
      "metadata": {},
      "outputs": [],
      "source": [
        "# handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    subscription_id=\"0ac7b36f-d0da-40e1-9e2a-3644bc3c6d6f\",\n",
        "    resource_group_name=\"dips-ml-studio\",\n",
        "    workspace_name=\"dips-ml-workspace\",\n",
        "    credential=credential,\n",
        ")\n",
        "\n",
        "cpu_cluster = None\n",
        "gpu_cluster = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41d3ce5e",
      "metadata": {},
      "source": [
        "### Provision the required resources for this notebook (Optional)\n",
        "\n",
        "We'll need 2 clusters for this notebook, a CPU cluster and a GPU cluster. First, let's create a minimal cpu cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a708daab",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ActivityCompleted: Activity=Compute.Get, HowEnded=Failure, Duration=883.9 [ms], Exception=ResourceNotFoundError, ErrorCategory=UserError, ErrorMessage=Operation returned an invalid status 'Not Found'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new cpu compute target...\n",
            "AMLCompute with name cpu-cluster is created, the compute size is STANDARD_DS3_V2\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "cpu_compute_target = \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        # Name assigned to the compute cluster\n",
        "        name=\"cpu-cluster\",\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_DS3_V2\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=4,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.begin_create_or_update(cpu_cluster).result()\n",
        "\n",
        "print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5481d489",
      "metadata": {},
      "source": [
        "For GPUs, we're creating the cluster below with the smallest VM family."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "027a2b2e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using serverless compute for GPU training (no pre-allocated cluster needed)\n",
            "This avoids quota limitations and auto-scales based on job requirements\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# GPU cluster creation is skipped due to subscription quota limitations\n",
        "# The training job will automatically use serverless compute instead\n",
        "# To enable GPU cluster creation, uncomment the code below after requesting quota increase\n",
        "\n",
        "# gpu_compute_target = \"gpu-cluster\"\n",
        "# \n",
        "# try:\n",
        "#     # let's see if the compute target already exists\n",
        "#     gpu_cluster = ml_client.compute.get(gpu_compute_target)\n",
        "#     print(\n",
        "#         f\"You already have a cluster named {gpu_compute_target}, we'll reuse it as is.\"\n",
        "#     )\n",
        "# \n",
        "# except Exception:\n",
        "#     print(\"Creating a new gpu compute target...\")\n",
        "# \n",
        "#     gpu_cluster = AmlCompute(\n",
        "#         name=\"gpu-cluster\",\n",
        "#         type=\"amlcompute\",\n",
        "#         size=\"STANDARD_NC6s_v3\",  # 1 x NVIDIA Tesla V100\n",
        "#         min_instances=0,\n",
        "#         max_instances=4,\n",
        "#         idle_time_before_scale_down=180,\n",
        "#         tier=\"Dedicated\",\n",
        "#     )\n",
        "# \n",
        "#     gpu_cluster = ml_client.begin_create_or_update(gpu_cluster).result()\n",
        "\n",
        "print(\"Using serverless compute for GPU training (no pre-allocated cluster needed)\")\n",
        "print(\"This avoids quota limitations and auto-scales based on job requirements\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "202ab207",
      "metadata": {},
      "source": [
        "# 1. Unpack a public image archives with a simple command (no code)\n",
        "\n",
        "To train our classifier, we'll consume the [Stanford Dogs Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) or the [Places2 dataset](http://places2.csail.mit.edu/download.html). If we were to use this locally, the sequence would be very basic: download a large tar archive, untar and put in different train/validation folders, upload to the cloud for consumption by the training script.\n",
        "\n",
        "We'll do just that, but in the cloud, without too much pain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08cca166",
      "metadata": {},
      "source": [
        "## 1.1. Unpack a first small dataset for testing\n",
        "\n",
        "The Azure ML SDK provides `entities` to implement any step of a workflow. In the example below, we create a `CommandJob` with just a shell command. We parameterize this command by using a string template syntax provided by the SDK:\n",
        "\n",
        "> ```\n",
        "> tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.images}}\n",
        "> ```\n",
        "\n",
        "Creating the component just consists in declaring the names of the inputs, outputs, and specifying an environment. For this simple job we'll use a curated environment from AzureML. After that, we'll be able to reuse that component multiple times in our pipeline design.\n",
        "\n",
        "Note: in this job, we're using an input type `uri_file` with a direct url. In this case, Azure ML will download the file from the url and provide it for the job to execute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e70c8d83",
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "dogs_dataset_command_job = command(\n",
        "    display_name=\"untar_dogs\",  # optional: this will show in the UI\n",
        "    # this component has no code, just a simple unzip command\n",
        "    command=\"tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.images}}\",\n",
        "    # I/O specifications, each using a specific key and type\n",
        "    inputs={\n",
        "        \"archive\": Input(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            path=\"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\",\n",
        "        )\n",
        "    },\n",
        "    outputs={\n",
        "        # two outputs, used in command as outputs.*\n",
        "        \"images\": Output(\n",
        "            type=AssetTypes.URI_FOLDER,\n",
        "            mode=\"upload\",\n",
        "            path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/dogs/\",\n",
        "        ),\n",
        "    },\n",
        "    # we're using a curated environment\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
        "    compute=\"cpu-cluster\"\n",
        "    if (cpu_cluster)\n",
        "    else None,  # No compute needs to be passed to use serverless\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "01415285",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The url to see your live job running is returned by the sdk:\n",
            "https://ml.azure.com/runs/crimson_soursop_f5kms842r1?wsid=/subscriptions/0ac7b36f-d0da-40e1-9e2a-3644bc3c6d6f/resourcegroups/dips-ml-studio/workspaces/dips-ml-workspace&tid=af8819b1-93b7-4fea-9207-fec6fcaeeb5a\n",
            "The pipeline details can be access programmatically using identifier: crimson_soursop_f5kms842r1\n"
          ]
        }
      ],
      "source": [
        "import webbrowser\n",
        "\n",
        "# submit the command\n",
        "returned_job = ml_client.create_or_update(\n",
        "    dogs_dataset_command_job,\n",
        ")\n",
        "\n",
        "# get a URL for the status of the job\n",
        "print(\"The url to see your live job running is returned by the sdk:\")\n",
        "print(returned_job.studio_url)\n",
        "# open the browser with this url\n",
        "webbrowser.open(returned_job.studio_url)\n",
        "\n",
        "# print the pipeline run id\n",
        "print(\n",
        "    f\"The pipeline details can be access programmatically using identifier: {returned_job.name}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f625a5",
      "metadata": {},
      "source": [
        "## 1.2. Unpack a second larger dataset for training [optional]\n",
        "\n",
        "If you'd like to test the distributed training job below with a more complex dataset, the code below will unpack the [Places2 dataset](http://places2.csail.mit.edu/download.html) dataset images, which has 1.8 million images in 365 categories. This will require a larger VM than the one you provisioned earlier. We recommend you provision a [STANDARD_DS12_V2](https://docs.microsoft.com/en-us/azure/virtual-machines/dv2-dsv2-series-memory). The code below will use compute cluster name `cpu-cluster-lg`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88190d2b",
      "metadata": {},
      "source": [
        "```python\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "places2_command_job = command(\n",
        "    display_name=\"untar_places2\",  # optional: this will show in the UI\n",
        "    # this component has no code, just a simple unzip command\n",
        "    command=\"&&\\n\".join(\n",
        "        [\n",
        "            # two lines of commands, one for training, one for validation\n",
        "            \"tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.valid_images}} places365_standard/val/\",\n",
        "            \"tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.train_images}} places365_standard/train/\",\n",
        "        ]\n",
        "    ),\n",
        "    # I/O specifications, each using a specific key and type\n",
        "    inputs={\n",
        "        \"archive\": Input(\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            path=\"http://data.csail.mit.edu/places/places365/places365standard_easyformat.tar\",\n",
        "        )\n",
        "    },\n",
        "    outputs={\n",
        "        # two outputs, used in command as outputs.*\n",
        "        \"train_images\": Output(\n",
        "            type=AssetTypes.URI_FOLDER,\n",
        "            mode=\"upload\",\n",
        "            path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/places2/train/\"\n",
        "        ),\n",
        "        \"valid_images\": Output(\n",
        "            type=AssetTypes.URI_FOLDER,\n",
        "            mode=\"upload\",\n",
        "            path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/places2/valid/\"\n",
        "        ),\n",
        "    },\n",
        "    # we're using a curated environment\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
        "    compute=\"cpu-cluster-lg\",\n",
        ")\n",
        "\n",
        "# submit the command\n",
        "returned_job = ml_client.create_or_update(places2_command_job)\n",
        "\n",
        "# get a URL for the status of the job\n",
        "print(\"The url to see your live job running is returned by the sdk:\")\n",
        "print(returned_job.studio_url)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e26664b",
      "metadata": {},
      "source": [
        "# 2. Training a distributed gpu job\n",
        "\n",
        "Implementing a distributed pytorch training is complex. Of course in this tutorial we've written one for you, but the point is: it takes time, it takes several iterations, each requiring you to try your code locally, then in the cloud, then try it at scale, until satisfied and then run a full blown production model training. This trial/error process can be made easier if we can create reusable code we can iterate on quickly, and that can be configured to run from small to large scale.\n",
        "\n",
        "So, to develop our training pipeline, we set a couple constraints for ourselves:\n",
        "- we want to minimize the effort to iterate on the pipeline code when porting it in the cloud,\n",
        "- we want to use the same code for small scale and large scale testing\n",
        "- we do not want to manipulate large data locally (ex: download/upload that data could take multiple hours),\n",
        "\n",
        "We've implemented a distributed pytorch training script that we can load as a command job. For this, we've decided to parameterize this job with relevant training arguments (see below).\n",
        "\n",
        "We can now test this code by running it on a smaller dataset in Azure ML. Here, we will use the dogs dataset both for training and validation. Of course, the model will not be valid. But training will be short (8 mins on 2 x STANDARD_NC6 for 1 epoch) to allow us to iterate if needed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d6681745",
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "training_job = command(\n",
        "    # local path where the code is stored\n",
        "    code=\"./src/pytorch_dl_train/\",\n",
        "    # describe the command to run the python script, with all its parameters\n",
        "    # use the syntax below to inject parameter values from code\n",
        "    command=\"\"\"python train.py \\\n",
        "        --train_images ${{inputs.train_images}} \\\n",
        "        --valid_images ${{inputs.valid_images}} \\\n",
        "        --batch_size ${{inputs.batch_size}} \\\n",
        "        --num_workers ${{inputs.num_workers}} \\\n",
        "        --prefetch_factor ${{inputs.prefetch_factor}} \\\n",
        "        --model_arch ${{inputs.model_arch}} \\\n",
        "        --model_arch_pretrained ${{inputs.model_arch_pretrained}} \\\n",
        "        --num_epochs ${{inputs.num_epochs}} \\\n",
        "        --learning_rate ${{inputs.learning_rate}} \\\n",
        "        --momentum ${{inputs.momentum}} \\\n",
        "        --register_model_as ${{inputs.register_model_as}} \\\n",
        "        --enable_profiling ${{inputs.enable_profiling}}\n",
        "    \"\"\",\n",
        "    inputs={\n",
        "        \"train_images\": Input(\n",
        "            type=\"uri_folder\",\n",
        "            path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/dogs/\",\n",
        "            # path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/places2/train/\",\n",
        "            mode=\"download\",  # use download to make access faster, mount if dataset is larger than VM\n",
        "        ),\n",
        "        \"valid_images\": Input(\n",
        "            type=\"uri_folder\",\n",
        "            path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/dogs/\",\n",
        "            # path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/places2/valid/\",\n",
        "            mode=\"download\",  # use download to make access faster, mount if dataset is larger than VM\n",
        "        ),\n",
        "        \"batch_size\": 64,\n",
        "        \"num_workers\": 5,  # number of cpus for pre-fetching\n",
        "        \"prefetch_factor\": 2,  # number of batches fetched in advance\n",
        "        \"model_arch\": \"resnet18\",\n",
        "        \"model_arch_pretrained\": True,\n",
        "        \"num_epochs\": 1,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"momentum\": 0.01,\n",
        "        \"register_model_as\": \"dogs_dev\",\n",
        "        # \"register_model_as\": \"places_dev\",\n",
        "        \"enable_profiling\": False,\n",
        "    },\n",
        "    environment=\"AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu@latest\",\n",
        "    compute=\"cpu-cluster\",\n",
        "    instance_count=1,\n",
        "    display_name=\"pytorch_training_sample_cpu\",\n",
        "    description=\"training a torchvision model on CPU (no quota needed)\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc7b9c5f",
      "metadata": {},
      "source": [
        "Once we create that job, we submit it through `MLClient`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8252fbc8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading pytorch_dl_train (0.04 MBs): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36710/36710 [00:00<00:00, 106264.86it/s]\u001b[0m\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The url to see your live job running is returned by the sdk:\n",
            "https://ml.azure.com/runs/gentle_milk_9f1v9kjypx?wsid=/subscriptions/0ac7b36f-d0da-40e1-9e2a-3644bc3c6d6f/resourcegroups/dips-ml-studio/workspaces/dips-ml-workspace&tid=af8819b1-93b7-4fea-9207-fec6fcaeeb5a\n",
            "The pipeline details can be access programmatically using identifier: gentle_milk_9f1v9kjypx\n"
          ]
        }
      ],
      "source": [
        "import webbrowser\n",
        "\n",
        "# submit the job\n",
        "returned_job = ml_client.jobs.create_or_update(\n",
        "    training_job,\n",
        "    # Project's name\n",
        "    experiment_name=\"e2e_image_sample\",\n",
        ")\n",
        "\n",
        "# get a URL for the status of the job\n",
        "print(\"The url to see your live job running is returned by the sdk:\")\n",
        "print(returned_job.studio_url)\n",
        "# open the browser with this url\n",
        "webbrowser.open(returned_job.studio_url)\n",
        "\n",
        "# print the pipeline run id\n",
        "print(\n",
        "    f\"The pipeline details can be access programmatically using identifier: {returned_job.name}\"\n",
        ")\n",
        "# saving it for later in this notebook\n",
        "small_scale_run_id = returned_job.name"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cf19ded",
      "metadata": {},
      "source": [
        "You can iterate on this design as much as you'd like, updating the local code of the job and re-submit the pipeline.\n",
        "\n",
        "Note: in the code above, we have commented out the lines you'd need to test this training job on the Places 2 dataset (1.8m images)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c782c68e",
      "metadata": {},
      "source": [
        "# 3. Analyze experiments using MLFlow\n",
        "\n",
        "Azure ML natively integrates with MLFlow so that if your code already supports MLFlow logging, you will not have to modify it to report your metrics within Azure ML. The component above is using MLFlow internally to report relevant metrics, logs and artifacts. Look for `mlflow` calls within the script `train.py`.\n",
        "\n",
        "To access this data in the Azure ML Studio, click on the component in the pipeline to open the Details panel, then choose the **Metrics** panel.\n",
        "\n",
        "You can also access those metrics programmatically using mlflow. We'll demo a couple examples below.\n",
        "\n",
        "## 3.1. Connect to Azure ML using MLFlow client\n",
        "\n",
        "Connecting to Azure ML using MLFlow required to `pip install azureml-mlflow mlflow` (both). You can use the `MLClient` to obtain a tracking uri to connect with the mlflow client. In the example below, we'll get all the runs related to the training experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6af554a2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/__init__.py:41: UserWarning: Versions of mlflow (3.1.1) and mlflow-skinny (2.22.1) are different. This may lead to unexpected behavior. Please install the same version of both packages.\n",
            "  mlflow.mismatch._check_version_mismatch()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>experiment_id</th>\n",
              "      <th>status</th>\n",
              "      <th>artifact_uri</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>metrics.epoch_train_loss</th>\n",
              "      <th>metrics.epoch_valid_acc</th>\n",
              "      <th>metrics.epoch_valid_loss</th>\n",
              "      <th>metrics.epoch_train_acc</th>\n",
              "      <th>...</th>\n",
              "      <th>params.cuda_device_count</th>\n",
              "      <th>params.num_epochs</th>\n",
              "      <th>params.learning_rate</th>\n",
              "      <th>params.num_workers</th>\n",
              "      <th>params.model_arch_pretrained</th>\n",
              "      <th>params.distributed_backend</th>\n",
              "      <th>tags.mlflow.runName</th>\n",
              "      <th>tags.mlflow.note.content</th>\n",
              "      <th>tags.mlflow.rootRunId</th>\n",
              "      <th>tags.mlflow.user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gentle_milk_9f1v9kjypx</td>\n",
              "      <td>ae826182-f10b-46be-8c90-197756e1159f</td>\n",
              "      <td>FINISHED</td>\n",
              "      <td></td>\n",
              "      <td>2025-11-14 14:59:27.569000+00:00</td>\n",
              "      <td>2025-11-14 15:43:31.432000+00:00</td>\n",
              "      <td>3.590557</td>\n",
              "      <td>0.033722</td>\n",
              "      <td>4.963666</td>\n",
              "      <td>0.27104</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>nccl</td>\n",
              "      <td>pytorch_training_sample_cpu</td>\n",
              "      <td>training a torchvision model on CPU (no quota ...</td>\n",
              "      <td>gentle_milk_9f1v9kjypx</td>\n",
              "      <td>Dipu Manandhar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   run_id                         experiment_id    status  \\\n",
              "0  gentle_milk_9f1v9kjypx  ae826182-f10b-46be-8c90-197756e1159f  FINISHED   \n",
              "\n",
              "  artifact_uri                       start_time  \\\n",
              "0              2025-11-14 14:59:27.569000+00:00   \n",
              "\n",
              "                          end_time  metrics.epoch_train_loss  \\\n",
              "0 2025-11-14 15:43:31.432000+00:00                  3.590557   \n",
              "\n",
              "   metrics.epoch_valid_acc  metrics.epoch_valid_loss  metrics.epoch_train_acc  \\\n",
              "0                 0.033722                  4.963666                  0.27104   \n",
              "\n",
              "   ...  params.cuda_device_count params.num_epochs params.learning_rate  \\\n",
              "0  ...                         0                 1                 0.01   \n",
              "\n",
              "  params.num_workers params.model_arch_pretrained params.distributed_backend  \\\n",
              "0                  5                            1                       nccl   \n",
              "\n",
              "           tags.mlflow.runName  \\\n",
              "0  pytorch_training_sample_cpu   \n",
              "\n",
              "                            tags.mlflow.note.content   tags.mlflow.rootRunId  \\\n",
              "0  training a torchvision model on CPU (no quota ...  gentle_milk_9f1v9kjypx   \n",
              "\n",
              "  tags.mlflow.user  \n",
              "0   Dipu Manandhar  \n",
              "\n",
              "[1 rows x 33 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import mlflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mlflow.set_tracking_uri(ml_client.workspaces.get().mlflow_tracking_uri)\n",
        "\n",
        "# search for the training step within the pipeline\n",
        "mlflow.set_experiment(\"e2e_image_sample\")\n",
        "\n",
        "# search for all runs and return as a pandas dataframe\n",
        "mlflow_runs = mlflow.search_runs()\n",
        "\n",
        "# display all runs as a dataframe in the notebook\n",
        "mlflow_runs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9bea13",
      "metadata": {},
      "source": [
        "## 3.2. Analyze metrics accross multiple jobs\n",
        "\n",
        "You can also use mlflow to search all your runs, filter by some specific properties and get the results as a pandas dataframe. Once you get that dataframe, you can implement any analysis on top of it.\n",
        "\n",
        "Below, we're extracting all runs and show the effect of profiling on the epoch training time.\n",
        "\n",
        "![mlflow runs in a pandas dataframe](./media/pytorch_train_mlflow_runs.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "477c5a0f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_id</th>\n",
              "      <th>status</th>\n",
              "      <th>end_time</th>\n",
              "      <th>metrics.epoch_train_time</th>\n",
              "      <th>metrics.epoch_train_acc</th>\n",
              "      <th>metrics.epoch_valid_acc</th>\n",
              "      <th>params.enable_profiling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gentle_milk_9f1v9kjypx</td>\n",
              "      <td>FINISHED</td>\n",
              "      <td>2025-11-14 15:43:31.432000+00:00</td>\n",
              "      <td>1205.232823</td>\n",
              "      <td>0.27104</td>\n",
              "      <td>0.033722</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   run_id    status                         end_time  \\\n",
              "0  gentle_milk_9f1v9kjypx  FINISHED 2025-11-14 15:43:31.432000+00:00   \n",
              "\n",
              "   metrics.epoch_train_time  metrics.epoch_train_acc  metrics.epoch_valid_acc  \\\n",
              "0               1205.232823                  0.27104                 0.033722   \n",
              "\n",
              "  params.enable_profiling  \n",
              "0                       0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "runs = mlflow.search_runs(\n",
        "    # we're using mlflow syntax to restrict to a specific parameter\n",
        "    filter_string=f\"params.model_arch = 'resnet18'\"\n",
        ")\n",
        "\n",
        "# we're keeping only some relevant columns\n",
        "columns = [\n",
        "    \"run_id\",\n",
        "    \"status\",\n",
        "    \"end_time\",\n",
        "    \"metrics.epoch_train_time\",\n",
        "    \"metrics.epoch_train_acc\",\n",
        "    \"metrics.epoch_valid_acc\",\n",
        "    \"params.enable_profiling\",\n",
        "]\n",
        "\n",
        "# showing the raw results in notebook\n",
        "runs[columns].dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c81fc568",
      "metadata": {},
      "source": [
        "## 3.3. Analyze the metrics of a specific job\n",
        "\n",
        "Using MLFlow, you can retrieve all the metrics produces by a given run. You can then leverage any usual tool to draw the analysis that is relevant for you. In the example below, we're plotting accuracy per epoch.\n",
        "\n",
        "![plot training and validation accuracy over epochs](./media/pytorch_train_mlflow_plot.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7969e008",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining results for run id gentle_milk_9f1v9kjypx\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x754d099e2350>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# here we're using the small scale training on validation data\n",
        "training_run_id = small_scale_run_id\n",
        "\n",
        "# alternatively, you can directly use a known training step id\n",
        "# training_run_id = \"...\"\n",
        "\n",
        "# open a client to get metric history\n",
        "client = MlflowClient()\n",
        "\n",
        "print(f\"Obtaining results for run id {training_run_id}\")\n",
        "\n",
        "# create a plot\n",
        "plt.rcdefaults()\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlabel(\"epoch\")\n",
        "\n",
        "for metric in [\"epoch_train_acc\", \"epoch_valid_acc\"]:\n",
        "    # get all values taken by the metric\n",
        "    try:\n",
        "        metric_history = client.get_metric_history(training_run_id, metric)\n",
        "    except:\n",
        "        print(f\"Metric {metric} could not be found in history\")\n",
        "        continue\n",
        "\n",
        "    epochs = [metric_entry.step for metric_entry in metric_history]\n",
        "    metric_array = [metric_entry.value for metric_entry in metric_history]\n",
        "    ax.plot(epochs, metric_array, label=metric)\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcb98d44",
      "metadata": {},
      "source": [
        "## 3.4. Retrieve artifacts for local analysis (ex: tensorboard)\n",
        "\n",
        "MLFlow also allows you to record artifacts during training. The script `train.py` leverages the [PyTorch profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html) to produce logs for analyzing GPU performance. It uses mlflow to record those logs as artifacts.\n",
        "\n",
        "To benefit from that, use the option `enable_profiling=True` in the submission code of section 2.\n",
        "\n",
        "In the following, we'll download those locally to inspect with other tools such as tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f2796344",
      "metadata": {},
      "outputs": [
        {
          "ename": "MlflowException",
          "evalue": "API request to endpoint /api/2.0/mlflow/logged-models/search failed with error code 404 != 200. Response body: ''",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# create local directory to store artefacts\u001b[39;00m\n\u001b[1;32m     13\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m artifact \u001b[38;5;129;01min\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_run_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprofiler/markdown/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading artifact \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m     client\u001b[38;5;241m.\u001b[39mdownload_artifacts(training_run_id, path\u001b[38;5;241m=\u001b[39martifact\u001b[38;5;241m.\u001b[39mpath, dst_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/tracking/client.py:3326\u001b[0m, in \u001b[0;36mMlflowClient.list_artifacts\u001b[0;34m(self, run_id, path)\u001b[0m\n\u001b[1;32m   3272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[FileInfo]:\n\u001b[1;32m   3273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"List the artifacts for a run.\u001b[39;00m\n\u001b[1;32m   3274\u001b[0m \n\u001b[1;32m   3275\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3324\u001b[0m \n\u001b[1;32m   3325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:679\u001b[0m, in \u001b[0;36mTrackingServiceClient.list_artifacts\u001b[0;34m(self, run_id, path)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"List the artifacts for a run.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \n\u001b[1;32m    668\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m \n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifacts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_artifacts\n\u001b[0;32m--> 679\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlist_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracking_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking_uri\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/artifacts/__init__.py:137\u001b[0m, in \u001b[0;36mlist_artifacts\u001b[0;34m(artifact_uri, run_id, artifact_path, tracking_uri)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Use `runs:/<run_id>/<artifact_path>` to list both run and model (if exists) artifacts\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id \u001b[38;5;129;01mand\u001b[39;00m artifact_path:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_artifact_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns:/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m store \u001b[38;5;241m=\u001b[39m _get_store(store_uri\u001b[38;5;241m=\u001b[39mtracking_uri)\n\u001b[1;32m    140\u001b[0m artifact_uri \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mget_run(run_id)\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39martifact_uri\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/store/artifact/runs_artifact_repo.py:123\u001b[0m, in \u001b[0;36mRunsArtifactRepository.list_artifacts\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlist_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[FileInfo]:\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    Return all the artifacts for this run_id directly under path. If path is a file, returns\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    an empty list. Will error if path is neither a file nor directory. When the run has an\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m        List of artifacts as FileInfo listed directly under path.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_run_artifacts(path) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_list_model_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/store/artifact/runs_artifact_repo.py:170\u001b[0m, in \u001b[0;36mRunsArtifactRepository._list_model_artifacts\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    168\u001b[0m [model_name, \u001b[38;5;241m*\u001b[39mrest] \u001b[38;5;241m=\u001b[39m rel_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    169\u001b[0m rel_path \u001b[38;5;241m=\u001b[39m rest[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m rest \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_logged_model_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    171\u001b[0m     artifacts \u001b[38;5;241m=\u001b[39m repo\u001b[38;5;241m.\u001b[39mlist_artifacts(path\u001b[38;5;241m=\u001b[39mrel_path)\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    173\u001b[0m         FileInfo(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, is_dir\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39mis_dir, file_size\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m.\u001b[39mfile_size)\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artifacts\n\u001b[1;32m    175\u001b[0m     ]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/store/artifact/runs_artifact_repo.py:154\u001b[0m, in \u001b[0;36mRunsArtifactRepository._get_logged_model_artifact_repo\u001b[0;34m(self, run_id, name)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         page_token \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matched \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_run_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_artifact_repository(matched\u001b[38;5;241m.\u001b[39martifact_location)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/store/artifact/runs_artifact_repo.py:154\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         page_token \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mtoken\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matched \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mnext\u001b[39m((m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m iter_models() \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39msource_run_id \u001b[38;5;241m==\u001b[39m run_id), \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_artifact_repository(matched\u001b[38;5;241m.\u001b[39martifact_location)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/store/artifact/runs_artifact_repo.py:143\u001b[0m, in \u001b[0;36mRunsArtifactRepository._get_logged_model_artifact_repo.<locals>.iter_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m page_token: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     page \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_logged_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# TODO: Filter by 'source_run_id' once Databricks backend supports it\u001b[39;49;00m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m page\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m page\u001b[38;5;241m.\u001b[39mtoken:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/tracking/client.py:5584\u001b[0m, in \u001b[0;36mMlflowClient.search_logged_models\u001b[0;34m(self, experiment_ids, filter_string, datasets, max_results, order_by, page_token)\u001b[0m\n\u001b[1;32m   5516\u001b[0m \u001b[38;5;129m@experimental\u001b[39m\n\u001b[1;32m   5517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch_logged_models\u001b[39m(\n\u001b[1;32m   5518\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5524\u001b[0m     page_token: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5525\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PagedList[LoggedModel]:\n\u001b[1;32m   5526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5527\u001b[0m \u001b[38;5;124;03m    Search for logged models that match the specified search criteria.\u001b[39;00m\n\u001b[1;32m   5528\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5582\u001b[0m \u001b[38;5;124;03m        :py:class:`LoggedModel <mlflow.entities.LoggedModel>` objects.\u001b[39;00m\n\u001b[1;32m   5583\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_logged_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_token\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:881\u001b[0m, in \u001b[0;36mTrackingServiceClient.search_logged_models\u001b[0;34m(self, experiment_ids, filter_string, datasets, max_results, order_by, page_token)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_ids, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(eid, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m eid \u001b[38;5;129;01min\u001b[39;00m experiment_ids\n\u001b[1;32m    877\u001b[0m ):\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException\u001b[38;5;241m.\u001b[39minvalid_parameter_value(\n\u001b[1;32m    879\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_ids must be a list of strings, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(experiment_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    880\u001b[0m     )\n\u001b[0;32m--> 881\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_logged_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder_by\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_token\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:1057\u001b[0m, in \u001b[0;36mRestStore.search_logged_models\u001b[0;34m(self, experiment_ids, filter_string, datasets, max_results, order_by, page_token)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;124;03mSearch for logged models that match the specified search criteria.\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;124;03m    :py:class:`LoggedModel <mlflow.entities.LoggedModel>` objects.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m   1034\u001b[0m     SearchLoggedModels(\n\u001b[1;32m   1035\u001b[0m         experiment_ids\u001b[38;5;241m=\u001b[39mexperiment_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     )\n\u001b[1;32m   1056\u001b[0m )\n\u001b[0;32m-> 1057\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSearchLoggedModels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1058\u001b[0m models \u001b[38;5;241m=\u001b[39m [LoggedModel\u001b[38;5;241m.\u001b[39mfrom_proto(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m response_proto\u001b[38;5;241m.\u001b[39mmodels]\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PagedList(models, response_proto\u001b[38;5;241m.\u001b[39mnext_page_token \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/store/tracking/rest_store.py:135\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[0m\n\u001b[1;32m    133\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m    134\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:590\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[0m\n\u001b[1;32m    587\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m    588\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 590\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m response_to_parse \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/mlflow/utils/rest_utils.py:310\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    307\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m         )\n\u001b[0;32m--> 310\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    311\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Response body: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    312\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mget_error_code(response\u001b[38;5;241m.\u001b[39mstatus_code),\n\u001b[1;32m    313\u001b[0m         )\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endpoint\u001b[38;5;241m.\u001b[39mstartswith(_REST_API_PATH_PREFIX) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n",
            "\u001b[0;31mMlflowException\u001b[0m: API request to endpoint /api/2.0/mlflow/logged-models/search failed with error code 404 != 200. Response body: ''"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# here we're using the small scale training on validation data\n",
        "training_run_id = small_scale_run_id\n",
        "\n",
        "# alternatively, you can directly use a known training step id\n",
        "# training_run_id = \"...\"\n",
        "\n",
        "# open a client to get metric history\n",
        "client = MlflowClient()\n",
        "\n",
        "# create local directory to store artefacts\n",
        "os.makedirs(\"./logs/\", exist_ok=True)\n",
        "\n",
        "for artifact in client.list_artifacts(training_run_id, path=\"profiler/markdown/\"):\n",
        "    print(f\"Downloading artifact {artifact.path}\")\n",
        "    client.download_artifacts(training_run_id, path=artifact.path, dst_path=\"./logs\")\n",
        "else:\n",
        "    print(f\"No artefacts were found for profiler/markdown/ in run id {training_run_id}\")\n",
        "\n",
        "for artifact in client.list_artifacts(\n",
        "    training_run_id, path=\"profiler/tensorboard_logs/\"\n",
        "):\n",
        "    print(f\"Downloading artifact {artifact.path}\")\n",
        "    client.download_artifacts(training_run_id, path=artifact.path, dst_path=\"./logs\")\n",
        "else:\n",
        "    print(f\"No artefacts were found for profiler/markdown/ in run id {training_run_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "631a3912",
      "metadata": {},
      "source": [
        "We can now run tensorboard locally with the downloaded artifacts to run some analysis of GPU performance (see example snapshot below).\n",
        "\n",
        "```\n",
        "tensorboard --logdir=\"./logs/profiler/tensorboard_logs/\"\n",
        "```\n",
        "\n",
        "![tensorboard logs generated by pytorch profiler](./media/pytorch_train_tensorboard_logs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f658d73",
      "metadata": {},
      "source": [
        "![](media/mlflow_plot.png)"
      ]
    }
  ],
  "metadata": {
    "categories": [
      "SDK v2",
      "tutorials"
    ],
    "description": {
      "description": "Prepare data, test and run a multi-node multi-gpu pytorch job. Use mlflow to analyze your metrics"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
